{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "%matplotlib inline\n",
    "#%config InlineBackend.figure_formats = ['svg']\n",
    "\n",
    "import tensorflow.compat.v2 as tf\n",
    "tf.enable_v2_behavior()\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import continuous_parameter_models as models\n",
    "import optimizers\n",
    "import sbn\n",
    "\n",
    "import importlib \n",
    "importlib.reload(models)\n",
    "importlib.reload(optimizers)\n",
    "importlib.reload(sbn)\n",
    "\n",
    "from continuous_parameter_models import TFContinuousParameterModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = sbn.instance(\"charlie\")\n",
    "data = \"primates\"\n",
    "if data == \"DS1\":\n",
    "    inst.read_newick_file(\"../data/ds1.raxml.tre\")\n",
    "    inst.read_fasta_file(\"../data/DS1.fasta\")\n",
    "    max_x = 0.02\n",
    "elif data == \"primates\":\n",
    "    inst.read_newick_file(\"../data/primates.tre\")\n",
    "    inst.read_fasta_file(\"../data/primates.fasta\")\n",
    "    max_x = 0.2\n",
    "elif data == \"hello\":\n",
    "    inst.tree_collection = sbn.TreeCollection(\n",
    "        [sbn.Tree.of_parent_id_vector([3, 3, 3])],\n",
    "        [\"mars\", \"saturn\", \"jupiter\"])\n",
    "    inst.read_fasta_file('../data/hello.fasta')\n",
    "    max_x = 0.4\n",
    "else:\n",
    "    assert False\n",
    "\n",
    "inst.make_beagle_instances(1)\n",
    "branch_lengths_extended = np.array(inst.tree_collection.trees[0].branch_lengths,\n",
    "                          copy=False)\n",
    "# Here we are getting a slice that excludes the last (fake) element. \n",
    "# Thus we can just deal with the actual branch lengths.\n",
    "branch_lengths = branch_lengths_extended[:len(branch_lengths_extended)-1]\n",
    "\n",
    "if data == \"hello\":\n",
    "    branch_lengths_extended[:] = np.array([0.2, 0.07, 0.07, 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_exp_prior(x, rate=10):\n",
    "    return np.log(rate) - np.sum(rate*x, axis=1)\n",
    "\n",
    "def grad_log_exp_prior(x, rate=10):\n",
    "    return -rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_like_with(in_branch_lengths, grad=False):\n",
    "    global branch_lengths\n",
    "    saved_branch_lengths = branch_lengths.copy()\n",
    "    branch_lengths[:] = in_branch_lengths\n",
    "    if grad:\n",
    "        _, log_grad = inst.branch_gradients()[0]\n",
    "        result = np.array(log_grad)\n",
    "    else:\n",
    "        result = np.array(inst.log_likelihoods())[0]\n",
    "        branch_lengths[:] = saved_branch_lengths\n",
    "    return result\n",
    "\n",
    "def phylo_log_like(x_arr):\n",
    "    \"\"\"\n",
    "    Calculate phylogenetic log likelihood for each of the branch length\n",
    "    assignments laid out along axis 1.\n",
    "    \"\"\"\n",
    "    return np.apply_along_axis(log_like_with, 1, x_arr)\n",
    "\n",
    "def grad_phylo_log_like(x_arr):\n",
    "    return np.apply_along_axis(lambda x: log_like_with(x, grad=True), 1, x_arr)[:,:-2]\n",
    "\n",
    "def phylo_log_upost(x_arr):\n",
    "    \"\"\"\n",
    "    The unnormalized phylogenetic posterior with an Exp(10) prior.\n",
    "    \"\"\"\n",
    "    return phylo_log_like(x_arr) + log_exp_prior(x_arr)\n",
    "\n",
    "def grad_phylo_log_upost(x_arr):\n",
    "    \"\"\"\n",
    "    The unnormalized phylogenetic posterior with an Exp(10) prior.\n",
    "    \"\"\"\n",
    "    return grad_phylo_log_like(x_arr) + grad_log_exp_prior(x_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m = TFContinuousParameterModel(models.gamma_factory, np.array([4., 20.]), len(branch_lengths), 100)\n",
    "#m = TFContinuousParameterModel(models.lognormal_factory, np.array([-2., 0.5]), len(branch_lengths), 100)\n",
    "m = TFContinuousParameterModel(models.truncated_lognormal_factory, np.array([-1., 0.5, 0.1]), len(branch_lengths), 100)\n",
    "m.mode_match(branch_lengths)\n",
    "m.elbo_estimate(phylo_log_upost, particle_count=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.AdaptiveStepsizeOptimizer(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opt.gradient_steps(phylo_log_upost, grad_phylo_log_upost, 25)\n",
    "opt.plot_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m.plot(phylo_log_like, max_x=max_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(sbn)\n",
    "\n",
    "mb_inst = sbn.instance(\"mb\")\n",
    "mb_inst.read_nexus_file(\"../_ignore/mb/DS1_out.t\")\n",
    "mb_inst.process_loaded_trees()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_inst.branch_lengths_by_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbn.instance.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([rootsplit[0] for rootsplit in mb_inst.get_indexer_representations()])\n",
    "assert (a == a[0,:]).all()\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.elbo_estimate(phylo_log_like, particle_count=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lognormal: -7153.707223708818"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* good: -2934.5720311158702\n",
    "* gamma with 200 steps: -2934.6846971854598\n",
    "* lognormal with 200 steps: -2934.636675260846"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot(phylo_log_like, max_x=max_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.elbo_estimate(phylo_log_like, particle_count=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot(phylo_log_like, max_x=max_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.elbo_estimate(phylo_log_like, particle_count=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as g:\n",
    "    tf_params = tf.constant(np.array([[-2., 0.5]]), dtype=tf.float32)\n",
    "    g.watch(tf_params)\n",
    "    q_distribution = lognormal_factory(tf_params)\n",
    "    mode_error = (0.025 - q_distribution.mode())**2\n",
    "    grad = g.gradient(mode_error, tf_params)\n",
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.optimizer = optimizers.SGD_Server({\"params\": m.param_matrix.shape})\n",
    "# %%timeit -n 1\n",
    "pd.DataFrame({\"bl\": np.log(branch_lengths), \"y\": m.param_matrix[:,1]}).plot.scatter(x=\"bl\", y=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    history[-1] = np.append(history[-1], m.elbo_estimate(phylo_log_like, particle_count=500))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 2.\n",
    "beta = 5.\n",
    "gamma = tfd.Gamma(concentration=alpha, rate=beta)\n",
    "\n",
    "def grad_log_like(x):\n",
    "    with tf.GradientTape() as g:\n",
    "        tf_x = tf.constant(x, dtype=tf.float32)\n",
    "        g.watch(tf_x)\n",
    "        return g.gradient(gamma.log_prob(tf_x), tf_x).numpy()\n",
    "\n",
    "def log_like(x):\n",
    "    return gamma.log_prob(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
