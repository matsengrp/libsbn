{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sbn\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "import tensorflow.compat.v2 as tf\n",
    "tf.enable_v2_behavior()\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import continuous_parameter_models as models\n",
    "import optimizers\n",
    "import sbn\n",
    "\n",
    "import importlib \n",
    "importlib.reload(models)\n",
    "importlib.reload(optimizers)\n",
    "importlib.reload(sbn)\n",
    "\n",
    "from continuous_parameter_models import TFContinuousParameterModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"DS1\"\n",
    "if data == \"DS1\":\n",
    "    nexus_file = \"../_ignore/mb/ds1/DS1_out.t\"\n",
    "    fasta_file = \"../data/DS1.fasta\"\n",
    "elif data == \"primates\":\n",
    "    nexus_file = \"../_ignore/mb/primates/primates_out.t\"\n",
    "    fasta_file = \"../_ignore/primates.fasta\"\n",
    "\n",
    "inst = sbn.instance(\"charlie\")\n",
    "inst.read_nexus_file(nexus_file)\n",
    "inst.process_loaded_trees()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "burn_in = int(0.1 * inst.tree_count())\n",
    "mb_branch_lengths = pd.DataFrame(\n",
    "    np.array([np.array(a) for a in inst.branch_lengths_by_split()])[:, burn_in:].transpose()\n",
    "    )\n",
    "mb_branch_lengths[\"total\"] = mb_branch_lengths.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst.read_fasta_file(fasta_file)\n",
    "inst.make_beagle_instances(1)\n",
    "inst.sample_trees(1)\n",
    "tree = inst.tree_collection.trees[0]\n",
    "branch_lengths_extended = np.array(tree.branch_lengths, copy=False)\n",
    "# Here we are getting a slice that excludes the last (fake) element. \n",
    "# Thus we can just deal with the actual branch lengths.\n",
    "branch_lengths = branch_lengths_extended[:len(branch_lengths_extended)-1]\n",
    "branch_lengths[:] = 0.1\n",
    "# The ith entry of this array gives the index of the split corresponding to the ith branch.\n",
    "branch_to_split = np.array(inst.get_psp_indexer_representations()[0][0])\n",
    "# The ith entry of this array gives the index of the branch corresponding to the ith split.\n",
    "split_to_branch=np.copy(branch_to_split)\n",
    "for branch in range(len(branch_to_split)):\n",
    "    split_to_branch[branch_to_split[branch]] = branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_branches_to_splits(branch_vector):\n",
    "    # The ith entry of this array is the entry corresponding to the ith split.\n",
    "    return branch_vector[split_to_branch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_like_with(split_lengths, grad=False):\n",
    "    global branch_lengths\n",
    "    saved_branch_lengths = branch_lengths.copy()\n",
    "    for branch in range(len(branch_lengths)):\n",
    "        branch_lengths[branch] = split_lengths[branch_to_split[branch]]\n",
    "    if grad:\n",
    "        _, log_grad = inst.branch_gradients()[0]\n",
    "        result = translate_branches_to_splits(np.array(log_grad)[:-2])\n",
    "    else:\n",
    "        result = np.array(inst.log_likelihoods())[0]\n",
    "        branch_lengths[:] = saved_branch_lengths\n",
    "    return result\n",
    "\n",
    "def phylo_log_like(x_arr):\n",
    "    \"\"\"\n",
    "    Calculate phylogenetic log likelihood for each of the branch length\n",
    "    assignments laid out along axis 1.\n",
    "    \"\"\"\n",
    "    return np.apply_along_axis(log_like_with, 1, x_arr)\n",
    "\n",
    "def grad_phylo_log_like(x_arr):\n",
    "    return np.apply_along_axis(lambda x: log_like_with(x, grad=True), 1, x_arr)\n",
    "\n",
    "def log_exp_prior(x, rate=10):\n",
    "    return np.log(rate) - np.sum(rate*x, axis=1)\n",
    "\n",
    "def grad_log_exp_prior(x, rate=10):\n",
    "    return -rate\n",
    "\n",
    "def phylo_log_upost(x_arr):\n",
    "    \"\"\"\n",
    "    The unnormalized phylogenetic posterior with an Exp(10) prior.\n",
    "    \"\"\"\n",
    "    return phylo_log_like(x_arr) + log_exp_prior(x_arr)\n",
    "\n",
    "def grad_phylo_log_upost(x_arr):\n",
    "    \"\"\"\n",
    "    The unnormalized phylogenetic posterior with an Exp(10) prior.\n",
    "    \"\"\"\n",
    "    return grad_phylo_log_like(x_arr) + grad_log_exp_prior(x_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m = TFContinuousParameterModel(models.gamma_factory, np.array([1.3, 3.]), len(branch_lengths), 100)\n",
    "m = TFContinuousParameterModel(models.lognormal_factory, np.array([-2., 0.5]), len(branch_lengths), 100)\n",
    "#m = TFContinuousParameterModel(models.truncated_lognormal_factory, np.array([-1., 0.5, 0.1]), len(branch_lengths), 100)\n",
    "#m.mode_match(translate_branches_to_splits(branch_lengths))\n",
    "m.elbo_estimate(phylo_log_upost, particle_count=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.AdaptiveStepsizeOptimizer(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.step_size /= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.stepsize_increasing = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.step_size, opt.stepsize_increasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt.trace = []\n",
    "opt.gradient_steps(phylo_log_upost, grad_phylo_log_upost, 100)\n",
    "opt_trace = pd.DataFrame({\"elbo\": opt.trace}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%R -i opt_trace -w 800 -h 400 -u px\n",
    "\n",
    "library(\"ggplot2\")\n",
    "library(\"cowplot\")\n",
    "\n",
    "normal = ggplot(opt_trace) + \n",
    "    theme_minimal() +\n",
    "    geom_line(aes(x=index, y=elbo))\n",
    "\n",
    "zoomed = ggplot(tail(opt_trace, nrow(opt_trace)/3)) + \n",
    "    theme_minimal() +\n",
    "    geom_line(aes(x=index, y=elbo))\n",
    "\n",
    "plot_grid(normal, zoomed, nrow=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_sample = pd.DataFrame(m.sample(len(mb_branch_lengths)))\n",
    "fit_sample[\"total\"] = fit_sample.sum(axis=1)\n",
    "fit_sample[\"type\"] = \"vb\"\n",
    "mb_branch_lengths[\"type\"] = \"mcmc\"\n",
    "plot_fit_df = pd.concat([fit_sample.melt(id_vars=\"type\"), mb_branch_lengths.melt(id_vars=\"type\")])\n",
    "plot_fit_df[\"variable\"] = plot_fit_df[\"variable\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i plot_fit_df -w 1600 -h 800 -u px\n",
    "\n",
    "library(\"ggplot2\")\n",
    "library(\"cowplot\")\n",
    "\n",
    "ggplot(plot_fit_df) + \n",
    "    theme_minimal_grid() +\n",
    "    theme(axis.text.x = element_text(angle = -25)) +\n",
    "    geom_density(aes(value, color=type)) +\n",
    "    facet_wrap(\"variable\", scales=\"free\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.elbo_estimate(phylo_log_upost, particle_count=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
